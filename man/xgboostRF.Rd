% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/classification.R
\name{xgboostRF}
\alias{xgboostRF}
\title{xgboost random forests algorithm}
\usage{
xgboostRF(train.ds = NULL, holdout.ds = NULL, validation.ds = NULL,
  label = "phenos", cv.folds = 10, num.threads = 2, num.rounds = c(1),
  max.depth = c(4), shrinkage = c(1), save.file = NULL, verbose = FALSE)
}
\arguments{
\item{train.ds}{A data frame with training data and class labels}

\item{holdout.ds}{A data frame with holdout data and class labels}

\item{validation.ds}{A data frame with validation data and class labels}

\item{label}{A character vector of the class variable column name}

\item{cv.folds}{An integer for the number of cross validation folds}

\item{num.threads}{An integer for OpenMP number of cores}

\item{num.rounds}{An integer number of xgboost boosting iterations}

\item{max.depth}{An integer aximum tree depth}

\item{shrinkage}{A numeric gradient learning rate 0-1}

\item{save.file}{A character vector for results filename or NULL to skip}

\item{verbose}{A flag indicating whether verbose output be sent to stdout}
}
\value{
A list containing:
\describe{
  \item{algo.acc}{data frame of results, a row for each update}
  \item{ggplot.data}{melted results data frame for plotting}
  \item{trn.model}{xgboost model}
  \item{elapsed}{total elapsed time}
}
}
\description{
Scalable and Flexible Gradient Boosting
XGBoost is short for “Extreme Gradient Boosting”, where the term “Gradient Boosting”
is proposed in the paper Greedy Function Approximation: A Gradient Boosting Machine,
by Friedman. XGBoost is based on this original model. This is a function using gradient
boosted trees for privacyEC.
}
\examples{
num.samples <- 100
num.variables <- 100
pct.signals <- 0.1
sim.data <- createSimulation(num.variables = num.variables,
                             num.samples = num.samples,
                             sim.type = "mainEffect",
                             pct.train = 1 / 3,
                             pct.holdout = 1 / 3,
                             pct.validation = 1 / 3,
                             verbose = FALSE)
rra.results <- xgboostRF(train.ds = sim.data$train,
                         holdout.ds = sim.data$holdout,
                         validation.ds = sim.data$validation,
                         label = sim.data$class.label,
                         num.rounds = c(1),
                         max.depth = c(10),
                         is.simulated = TRUE,
                         verbose = FALSE,
                         signal.names = sim.data$signal.names)
}
\seealso{
Other classification: \code{\link{epistasisRank}},
  \code{\link{getImportanceScores}},
  \code{\link{originalThresholdout}},
  \code{\link{privateEC}}, \code{\link{privateRF}},
  \code{\link{standardRF}}
}
