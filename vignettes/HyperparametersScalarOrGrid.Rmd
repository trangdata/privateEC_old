---
title: "Hyperparameters: Scalars or Vectors"
author: "Bill White"
date: "`r Sys.Date()`"
output: pdf_document
vignette: >
  %\VignetteIndexEntry{Learner Hyperparameters}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(privateEC)
```

## privateEC Learner Hyperparameters

* Scalar: fixed runs
* Vector: many runs over a grid of parameter combinations

## Relief-F + xgboost fixed parameters

Hyperparameters for caret-based learners can accept scalars and/or vectors. This
example uses scalars, therefore a "degenerate" one dimensional grid.

### Simulate 100 subjects by one hundred variables, 10 with main effects against background noise, and split into train, holdout and test data sets.

```{r, echo=TRUE}
  num.samples <- 100
  num.variables <- 100
  pct.signals <- 0.1
  sim.data <- createSimulation(num.samples = num.samples,
                               num.variables = num.variables,
                               pct.signals = pct.signals,
                               pct.train = 1 / 3,
                               pct.holdout = 1 / 3,
                               pct.validation = 1 / 3,
                               sim.type = "mainEffect",
                               verbose = FALSE)
```
  
### Run with scalar hyperparameters  
  
```{r, echo=TRUE}
  hyper.rounds <- 1
  hyper.depth <- 4
  hyper.shrink <- 1.0
  pec.results.scalar <- privateEC(train.ds = sim.data$train,
                                  holdout.ds = sim.data$holdout,
                                  validation.ds = sim.data$validation,
                                  label = sim.data$class.label,
                                  importance.name = "relieff",
                                  importance.algorithm = "ReliefFBestK",
                                  learner.name = "xgboost",
                                  xgb.num.rounds = hyper.rounds,
                                  xgb.max.depth = hyper.depth,
                                  xgb.shrinkage = hyper.shrink,
                                  is.simulated = TRUE,
                                  signal.names = sim.data$signal.names,
                                  verbose = FALSE)
  
```

```{r, echo=FALSE, fig.height = 4, fig.width = 6, fig.align = "center"}
plotRunResults(pec.results.scalar)
```

## Relief-F + xgboost with hyperparameter optimization

To do a grid search on the learner hyperparameters, use a vector instead of a scalar.
This example creates a 3-dimensional grid of parameter values for the xgboost learner.

```{r, echo=TRUE}
  hyper.rounds <- c(1, 2, 3)
  hyper.depth <- c(2, 4, 8)
  hyper.shrink <- c(0.1, 0.5, 1.0)
  pec.results.grid <- privateEC(train.ds = sim.data$train,
                                holdout.ds = sim.data$holdout,
                                validation.ds = sim.data$validation,
                                label = sim.data$class.label,
                                importance.name = "relieff",
                                importance.algorithm = "ReliefFBestK",
                                learner.name = "xgboost",
                                xgb.num.rounds = hyper.rounds,
                                xgb.max.depth = hyper.depth,
                                xgb.shrinkage = hyper.shrink,
                                is.simulated = TRUE,
                                signal.names = sim.data$signal.names,
                                verbose = FALSE)
```

```{r, echo=FALSE, fig.height = 4, fig.width = 6, fig.align = "center"}
plotRunResults(pec.results.grid)
```

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
